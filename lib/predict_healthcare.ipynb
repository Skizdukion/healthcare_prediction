{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pyspark.ml import Pipeline\n",
    "from __future__ import print_function\n",
    "import seaborn as sns\n",
    "import imblearn\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import math \n",
    "import pyspark.sql.functions as F\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate();\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"HealthCarePrediction\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+----+------------+-------------+------------+-------------+--------------+-----------------+----+---------------+------+\n",
      "|   id|gender| age|hypertension|heart_disease|ever_married|    work_type|Residence_type|avg_glucose_level| bmi| smoking_status|stroke|\n",
      "+-----+------+----+------------+-------------+------------+-------------+--------------+-----------------+----+---------------+------+\n",
      "| 9046|  Male|67.0|           0|            1|         Yes|      Private|         Urban|           228.69|36.6|formerly smoked|     1|\n",
      "|51676|Female|61.0|           0|            0|         Yes|Self-employed|         Rural|           202.21| N/A|   never smoked|     1|\n",
      "|31112|  Male|80.0|           0|            1|         Yes|      Private|         Rural|           105.92|32.5|   never smoked|     1|\n",
      "|60182|Female|49.0|           0|            0|         Yes|      Private|         Urban|           171.23|34.4|         smokes|     1|\n",
      "| 1665|Female|79.0|           1|            0|         Yes|Self-employed|         Rural|           174.12|  24|   never smoked|     1|\n",
      "|56669|  Male|81.0|           0|            0|         Yes|      Private|         Urban|           186.21|  29|formerly smoked|     1|\n",
      "|53882|  Male|74.0|           1|            1|         Yes|      Private|         Rural|            70.09|27.4|   never smoked|     1|\n",
      "|10434|Female|69.0|           0|            0|          No|      Private|         Urban|            94.39|22.8|   never smoked|     1|\n",
      "|27419|Female|59.0|           0|            0|         Yes|      Private|         Rural|            76.15| N/A|        Unknown|     1|\n",
      "|60491|Female|78.0|           0|            0|         Yes|      Private|         Urban|            58.57|24.2|        Unknown|     1|\n",
      "|12109|Female|81.0|           1|            0|         Yes|      Private|         Rural|            80.43|29.7|   never smoked|     1|\n",
      "|12095|Female|61.0|           0|            1|         Yes|     Govt_job|         Rural|           120.46|36.8|         smokes|     1|\n",
      "|12175|Female|54.0|           0|            0|         Yes|      Private|         Urban|           104.51|27.3|         smokes|     1|\n",
      "| 8213|  Male|78.0|           0|            1|         Yes|      Private|         Urban|           219.84| N/A|        Unknown|     1|\n",
      "| 5317|Female|79.0|           0|            1|         Yes|      Private|         Urban|           214.09|28.2|   never smoked|     1|\n",
      "|58202|Female|50.0|           1|            0|         Yes|Self-employed|         Rural|           167.41|30.9|   never smoked|     1|\n",
      "|56112|  Male|64.0|           0|            1|         Yes|      Private|         Urban|           191.61|37.5|         smokes|     1|\n",
      "|34120|  Male|75.0|           1|            0|         Yes|      Private|         Urban|           221.29|25.8|         smokes|     1|\n",
      "|27458|Female|60.0|           0|            0|          No|      Private|         Urban|            89.22|37.8|   never smoked|     1|\n",
      "|25226|  Male|57.0|           0|            1|          No|     Govt_job|         Urban|           217.08| N/A|        Unknown|     1|\n",
      "+-----+------+----+------------+-------------+------------+-------------+--------------+-----------------+----+---------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rawDF = spark.read.csv('healthcare-dataset-stroke-data.csv', header=True, inferSchema=True)\n",
    "rawDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawDF = rawDF.dropna()\n",
    "rawDF = rawDF.filter(rawDF['bmi'] != \"N/A\")\n",
    "rawDF = rawDF.filter(rawDF['gender'] != \"Other\")\n",
    "rawDF = rawDF.withColumn(\"bmi\",rawDF.bmi.cast('double'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StandardScaler, StringIndexer, VectorAssembler\n",
    "cat_features = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
    "stringIndexedDF = rawDF\n",
    "for features in cat_features:\n",
    "    # Index Categorical Features\n",
    "    string_indexer = StringIndexer(inputCol=features, outputCol=features + \"_index\")\n",
    "    stringIndexedDF = string_indexer.fit(stringIndexedDF).transform(stringIndexedDF)\n",
    "for features in cat_features:     \n",
    "    stringIndexedDF = stringIndexedDF.withColumn(features+\"_index\",stringIndexedDF[features+\"_index\"].cast('int'))\n",
    "\n",
    "stringIndexedDF = stringIndexedDF.drop(*cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- hypertension: integer (nullable = true)\n",
      " |-- heart_disease: integer (nullable = true)\n",
      " |-- avg_glucose_level: double (nullable = true)\n",
      " |-- bmi: double (nullable = true)\n",
      " |-- stroke: integer (nullable = true)\n",
      " |-- gender_index: integer (nullable = true)\n",
      " |-- ever_married_index: integer (nullable = true)\n",
      " |-- work_type_index: integer (nullable = true)\n",
      " |-- Residence_type_index: integer (nullable = true)\n",
      " |-- smoking_status_index: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stringIndexedDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = stringIndexedDF.drop('stroke')\n",
    "Y = stringIndexedDF.select('stroke')\n",
    "stk = SMOTE(random_state=42)\n",
    "X_res,y_res = stk.fit_resample(X.toPandas(),Y.toPandas())\n",
    "joinDF = pd.concat([X_res, y_res], axis=1, join=\"inner\")\n",
    "balancedData = spark.createDataFrame(joinDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- hypertension: long (nullable = true)\n",
      " |-- heart_disease: long (nullable = true)\n",
      " |-- avg_glucose_level: double (nullable = true)\n",
      " |-- bmi: double (nullable = true)\n",
      " |-- gender_index: long (nullable = true)\n",
      " |-- ever_married_index: long (nullable = true)\n",
      " |-- work_type_index: long (nullable = true)\n",
      " |-- Residence_type_index: long (nullable = true)\n",
      " |-- smoking_status_index: long (nullable = true)\n",
      " |-- stroke: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "balancedData.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features_to_scale(df=balancedData, lower_skew=-2, upper_skew=2, dtypes='double'):\n",
    "    \n",
    "    # Empty Selected Feature List for Output\n",
    "    selected_features = []\n",
    "    \n",
    "    # Select Features to Scale based on Inputs ('in32' type, drop 'ID' columns or others, skew bounds)\n",
    "    feature_list = list(df.toPandas().select_dtypes(include=[dtypes]).columns)\n",
    "    \n",
    "    # Loop through 'feature_list' to select features based on Kurtosis / Skew\n",
    "    for feature in feature_list:\n",
    "\n",
    "        if df.toPandas()[feature].kurtosis() < -2 or df.toPandas()[feature].kurtosis() > 2:\n",
    "            \n",
    "            selected_features.append(feature)\n",
    "    \n",
    "    # Return feature list to scale\n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_features = ['gender_index', 'ever_married_index', 'work_type_index', 'Residence_type_index', 'smoking_status_index']\n",
    "\n",
    "encoderDF = balancedData\n",
    "\n",
    "for features in index_features:\n",
    "    encoder = OneHotEncoder(inputCols=[string_indexer.getOutputCol()],\n",
    "                                    outputCols=[features + \"_class_vec\"])\n",
    "    encoderDF = encoder.fit(encoderDF).transform(encoderDF)\n",
    "\n",
    "encoderDF = encoderDF.drop(*index_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'stroke'\n",
    "stages = []\n",
    "num_features = ['age','hypertension', 'heart_disease', 'avg_glucose_level', 'bmi']\n",
    "label_str_index =  StringIndexer(inputCol=label, outputCol=\"label_index\")\n",
    "\n",
    "# Scale Feature: Select the Features to Scale using helper 'select_features_to_scale' function above and Standardize \n",
    "unscaled_features = select_features_to_scale(df=encoderDF, lower_skew=-2, upper_skew=2, dtypes='double')\n",
    "\n",
    "unscaled_assembler = VectorAssembler(inputCols=unscaled_features, outputCol=\"unscaled_features\")\n",
    "scaler = StandardScaler(inputCol=\"unscaled_features\", outputCol=\"scaled_features\")\n",
    "\n",
    "stages += [unscaled_assembler, scaler]\n",
    "\n",
    "# Create list of Numeric Features that Are Not Being Scaled\n",
    "num_unscaled_diff_list = list(set(num_features) - set(unscaled_features))\n",
    "\n",
    "# Assemble or Concat the Categorical Features and Numeric Features\n",
    "assembler_inputs = [feature + \"_class_vec\" for feature in index_features] + num_unscaled_diff_list\n",
    "\n",
    "assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"assembled_inputs\") \n",
    "\n",
    "stages += [label_str_index, assembler]\n",
    "\n",
    "# Assemble Final Training Data of Scaled, Numeric, and Categorical Engineered Features\n",
    "assembler_final = VectorAssembler(inputCols=[\"scaled_features\",\"assembled_inputs\"], outputCol=\"features\")\n",
    "\n",
    "stages += [assembler_final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Pipeline\n",
    "pipeline = Pipeline(stages=stages)\n",
    "\n",
    "# Fit Pipeline to Data\n",
    "pipeline_model = pipeline.fit(encoderDF)\n",
    "\n",
    "# Transform Data using Fitted Pipeline\n",
    "df_transform = pipeline_model.transform(encoderDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So lan xuat hien cua stroke la 0:  4699\n",
      "So lan xuat hien cua stroke la 1:  4699\n"
     ]
    }
   ],
   "source": [
    "df_transform_fin = df_transform.select('features','label_index')\n",
    "# df_transform_fin.show()\n",
    "# df_transform_fin.count()\n",
    "print (\"So lan xuat hien cua stroke la 0: \",df_transform_fin.filter(df_transform_fin['label_index'] == 0).count())\n",
    "print (\"So lan xuat hien cua stroke la 1: \",df_transform_fin.filter(df_transform_fin['label_index'] == 1).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.803539183820874\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(labelCol=\"label_index\", featuresCol=\"features\")\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "train_data, test_data = df_transform_fin.randomSplit([.7, .3],seed=1234)\n",
    "model = dt.fit(train_data)\n",
    "predictions = model.transform(test_data)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label_index\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "model.save('model/decision_tree')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8061579651941098\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol=\"label_index\", featuresCol=\"features\", numTrees=10)\n",
    "train_data, test_data = df_transform_fin.randomSplit([.6, .4],seed=1234)\n",
    "rfModel = rf.fit(train_data)\n",
    "predictions = rfModel.transform(test_data)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label_index\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "rfModel.save('model/random_forest')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.17424\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "gbt = GBTClassifier(labelCol=\"label_index\", featuresCol=\"features\", maxIter=10)\n",
    "train_data, test_data = df_transform_fin.randomSplit([.7, .3],seed=1534)\n",
    "gbtModel = gbt.fit(train_data)\n",
    "gbtPredictions = gbtModel.transform(test_data)\n",
    "accuracy = evaluator.evaluate(gbtPredictions)\n",
    "gbtModel.save('model/gbt')\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "df989ace8a8da28cb7f7d1a12e3b4afec8c680846e24e9f4f7f420bf9f1fadcc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
